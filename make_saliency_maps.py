import os
import torch
import argparse
from torch import nn
from PIL import Image
from pathlib import Path
import torchvision.transforms as transforms
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader, Dataset
from helper import models, saliency_calculations


class CustomImageDataset(Dataset):
    def __init__(self, main_dir, transform=None):
        self.main_dir = Path(main_dir)
        self.transform = transform
        self.all_imgs = list(p for p in self.main_dir.rglob('*') if p.is_file())

    def __len__(self):
        return len(self.all_imgs)

    def __getitem__(self, idx):
        img_loc = self.all_imgs[idx]
        image = Image.open(img_loc)
        if self.transform is not None:
            image = self.transform(image)
        return image, img_loc.name


parser = argparse.ArgumentParser(description="Script to convert APK images into saliency maps.")
parser.add_argument("-e", "--experiment", help="Name of the experiment.")
args = parser.parse_args()

# MODEL_NAME = "model_training/_models/50_epochs_lr_0.0001_p_0.3.pth"
MODEL_NAME = "model_training/_models/DexrayOverTime5_classWeight_50epochs_lr_0.0001_p_0.3.pth"
IMG_SIZE = 128
DROPOUT = 0.3
BATCH_SIZE = 256

if args.experiment:
    images_directory = Path("pixel_to_code/_original_images") / args.experiment
    saliencies_directory = Path("pixel_to_code/_saliency_maps") / args.experiment

else:
    images_directory = Path("_resized_img_128")
    saliencies_directory = Path("_all_saliency_maps")
    

os.makedirs(images_directory, exist_ok=True)
os.makedirs(saliencies_directory, exist_ok=True)

# Setup
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = models.DexRayModel(IMG_SIZE, DROPOUT).to(device)
model.load_state_dict(torch.load(MODEL_NAME))


transform = transforms.Compose(
    [
        transforms.Grayscale(),
        transforms.ToTensor(),
        transforms.Lambda(lambda x: x.view(-1)),
    ]
)


dataset = CustomImageDataset(main_dir=images_directory, transform=transform)
dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)

class_weights = torch.tensor([1.0, 70/30], dtype=torch.float).to(device)
criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights[1])

saliency_calculations.save_images_and_saliencies_v2(
    dataloader=dataloader,
    folder=saliencies_directory,
    model=model,
    device=device,
    criterion=criterion,
)