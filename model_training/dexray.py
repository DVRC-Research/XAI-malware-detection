import argparse
import os
from pathlib import Path
import torch
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
from torchvision import transforms
from tqdm import tqdm
from helper import data_setup, engine, models, utils


parser = argparse.ArgumentParser(
    description="Script to train and test DexRay model",
    formatter_class=argparse.ArgumentDefaultsHelpFormatter,
)

parser.add_argument(
    "-lr",
    "--learning_rate",
    choices=[0.001, 0.0001],
    type=float,
    default=0.0001,
    help="learning rate",
)
parser.add_argument(
    "-p",
    "--proba",
    choices=[0, 0.1, 0.2, 0.3, 0.4, 0.5],
    type=float,
    default=0.3,
    help="dropout_rate",
)

args = parser.parse_args()


# Initialize TensorBoard writer
experiment_name = "DexRay_Over_Time"
model_name = f"50_epochs_lr_{args.learning_rate}_p_{args.proba}"
writer = engine.create_writer(experiment_name=experiment_name, model_name=model_name)

os.makedirs("model_training/_models", exist_ok=True)
image_path = Path("_resized_img_128")
train_dir = image_path / "train"
test_dir = image_path / "test"

IMG_SIZE = 128
BATCH_SIZE = 240
EPOCHS = 10

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


transform = transforms.Compose(
    [
        transforms.Grayscale(),
        transforms.ToTensor(),
        transforms.Lambda(lambda x: x.view(-1)),
    ]
)


train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(
    train_dir=train_dir,
    test_dir=test_dir,
    transform=transform,
    batch_size=BATCH_SIZE,
)


# Mitigate the effect of the imbalanced dataset between Goodwares and Malwares
weight_for_goodware = 1.0
weight_for_malware = (70 / 30)
class_weights = torch.tensor([weight_for_goodware, weight_for_malware], dtype=torch.float).to(device)



# Initialize the model
model = models.DexRayModel(IMG_SIZE, args.proba).to(device)
loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=class_weights[1])
optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)


# Training
for epoch in range(EPOCHS):
    model.train()
    running_loss = 0.0
    correct_train = 0
    total_train = 0

    for i, (inputs, labels) in tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=f"Epoch {epoch+1}/{EPOCHS}"):
        inputs, labels = inputs.to(device), labels.to(device).float()
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = loss_fn(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        predicted = torch.sigmoid(outputs).squeeze() > 0.5
        correct_train += (predicted == labels).sum().item()
        total_train += labels.size(0)

        writer.add_scalar('Training Loss', loss.item(), epoch * len(train_dataloader) + i)

    train_accuracy = 100 * correct_train / total_train
    writer.add_scalar('Training accuracy', train_accuracy, epoch)
    print(f"Epoch [{epoch+1}/{EPOCHS}], Training Loss: {running_loss/len(train_dataloader):.4f}, Training Accuracy: {train_accuracy:.2f}%")

    
    # /!\ Using test data for validation
    model.eval()
    val_loss = 0.0
    correct_val = 0
    total_val = 0
    with torch.no_grad():
        for inputs, labels in test_dataloader:
            inputs, labels = inputs.to(device), labels.to(device).float()
            outputs = model(inputs)
            val_loss += loss_fn(outputs, labels).item()
            predicted = torch.sigmoid(outputs).squeeze() > 0.5
            correct_val += (predicted == labels).sum().item()
            total_val += labels.size(0)

        val_loss /= len(test_dataloader)
        val_accuracy = 100 * correct_val / total_val
        writer.add_scalar('Validation Loss', val_loss, epoch)
        writer.add_scalar('Validation Accuracy', val_accuracy, epoch)
        print(f"Epoch [{epoch+1}/{EPOCHS}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%")

    

# Save the trained model
save_filepath = f"_models/{model_name}.pth"
utils.save_model(
    model=model, target_dir="model_training", model_name=save_filepath
)



# Evaluate the model

model.eval()
all_preds = []
all_labels = []

with torch.no_grad():
    for i, (inputs, labels) in tqdm(enumerate(test_dataloader), total=len(test_dataloader), desc="Evaluating"):
        inputs, labels = inputs.to(device), labels.to(device).float()

        outputs = model(inputs)
        preds = torch.sigmoid(outputs).squeeze() > 0.5
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

accuracy = accuracy_score(all_labels, all_preds)
recall = recall_score(all_labels, all_preds)
precision = precision_score(all_labels, all_preds)
f1 = f1_score(all_labels, all_preds)


with open("model_training/performance.txt", "a") as f:
    f.write(f"Model: {model_name}\n")
    f.write(f"Accuracy: {accuracy:.4f}\n")
    f.write(f"F1 Score: {f1:.2f}\n")
    f.write(f"Recall: {recall:.2f}\n")
    f.write(f"Precision: {precision:.2f}\n")
    f.write("\n\n")


writer.close()